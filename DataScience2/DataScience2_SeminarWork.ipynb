{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Science 2 - Seminar Work - prediction through classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this seminar work is to create a prediction through classification of the arxiv dataset. This dataset is a dataset of scholarly articels from the vast branches of science. It contains 1.7 millions data sampels with 176 diffrent categories and with this structure:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "id: ArXiv ID (can be used to access the paper, see below)\n",
    "submitter: Who submitted the paper\n",
    "authors: Authors of the paper\n",
    "title: Title of the paper\n",
    "comments: Additional info, such as number of pages and figures\n",
    "journal-ref: Information about the journal the paper was published in\n",
    "doi: (Digital Object Identifier)\n",
    "abstract: The abstract of the paper\n",
    "categories: Categories / tags in the ArXiv system\n",
    "versions: A version history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this dataset I tried to make a prediction about the category of an article through the abstract of the article. In this case it was particularly difficult as this is a multilabel dataset. Specifically, this means that an article can belong to several categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find the best possible model for this application, I tried several models with only 100000 sampels of the 1.7 million arxiv dataset. They were Decision Tree, Random Forest, Bagging Model, LinearSVC, Power Set SVC Model, Boosting Model, Multinomial Naive Bayes Model and k-nearest neighbors. Based on the metric results of the classification report, I decided in favor of the LinearSVC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import the needed libraries like nltk, scikitlearn and pandas. Those are necessary for the handling of dataframes and to work with text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\marin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn import model_selection\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "nltk.download('wordnet')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load the arxiv dataset into a dataframe. In a previous step, the dataset was already downloaded as a JSON file. After that, we split the dataset into train and test for abstract and categories. We will give out the timestamp of diffrent steps of our process to have a good overview over the computing time of these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "2021-01-05 21:32:14.891001\n",
      "Training sampels: 1412550\n",
      "Testing sampels: 353138\n"
     ]
    }
   ],
   "source": [
    "print(\"START\")\n",
    "print(datetime.datetime.now())\n",
    "df = pd.read_json('arxiv-metadata-oai-snapshot.json', lines=True)\n",
    "df.dropna()\n",
    "train_abstracts, test_abstracts, train_categories, test_categories = model_selection.train_test_split(df['abstract'], df['categories'],\n",
    "                                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training sampels:\", len(train_abstracts))\n",
    "print(\"Testing sampels:\", len(test_abstracts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the splitting, we need to take care of the categories. In our case, we have a multilabel dataset. Therefore, one article can be assigned to more than one category. For this, we use the MultiLabelBinarizer to transform the multi-categories. After that, we create new dataframes which contain only the abtract texts, which we need in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform(train_categories)\n",
    "test_labels = mlb.transform(test_categories)\n",
    "\n",
    "trainData = {\"abstract\": train_abstracts}\n",
    "testData = {\"abstract\": test_abstracts}\n",
    "trainDf = pd.DataFrame(trainData, columns=[\"abstract\"])\n",
    "testDf = pd.DataFrame(testData, columns=[\"abstract\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we carry out the preprocessing of the abstract text. For this, we use the WordNetLemmatizer and the PorterStemmer from nltk. First we replace the line breacks with empty. After that, we convert the text to lowercase and tokenize it. Then we need to check if the string contains only alphabetic characters only. Next, we need to perform the lemmatization and stemming to convert the words into their origin form. Finally, we remove the word which are shorter than 2 characters and stopwords because they don't give us value for our later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "stopwords = set(words.rstrip() for words in stopwords.words('english'))\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    tokens = nltk.tokenize.word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalpha()]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    tokens = [token for token in tokens if len(token) > 2]\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "    cleanedText = \" \".join(tokens)\n",
    "    return cleanedText\n",
    "\n",
    "def cleaning(df):\n",
    "    data = df.copy()\n",
    "    data[\"abstract\"] = data[\"abstract\"].apply(preprocessing)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the preprocessing of the text, we need to create tfidf vectors as an input for our classification later with the training and testing dataframes. For this, we use the TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREPROCESSED\n",
      "2021-01-05 22:48:01.284221\n",
      "DATA VECTORIZED\n",
      "2021-01-05 22:49:13.152078\n"
     ]
    }
   ],
   "source": [
    "cleanedTrainData = cleaning(trainDf)\n",
    "cleanedTestData = cleaning(testDf)\n",
    "print(\"DATA PREPROCESSED\")\n",
    "print(datetime.datetime.now())\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorised_train_abstracts = vectorizer.fit_transform(cleanedTrainData[\"abstract\"])\n",
    "vectorised_test_abstracts = vectorizer.transform(cleanedTestData[\"abstract\"])\n",
    "print(\"DATA VECTORIZED\")\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last step, we train the LinearSVC with our training data. We also need to use the OneVsRestClassifier, which creates a classifier for each categories. After the training process is finished, we predict the abstracts from the testing dataframe. From this prediction, we can compare the prediction result with the original categories. To have a good overview about the performance of our classification, we give a classification report. It contains the precision, recall and f1 and we give also the accuracy and hamming loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION START\n",
      "2021-01-05 22:49:13.160028\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.55    150525\n",
      "           1       0.96      0.95      0.96    223989\n",
      "           2       0.92      0.95      0.93    263754\n",
      "           3       0.77      0.54      0.64     55793\n",
      "           4       0.71      0.36      0.48      2228\n",
      "           5       0.75      0.53      0.62     62883\n",
      "           6       0.78      0.46      0.58     23186\n",
      "           7       0.74      0.42      0.54     21260\n",
      "           8       0.76      0.32      0.45      5971\n",
      "           9       0.77      0.56      0.65     48603\n",
      "          10       0.73      0.34      0.46     13413\n",
      "          11       0.75      0.45      0.57     24988\n",
      "          12       0.69      0.18      0.29       901\n",
      "          13       0.79      0.64      0.71     23390\n",
      "          14       0.67      0.26      0.37     36384\n",
      "          15       0.78      0.47      0.59     18892\n",
      "          16       0.75      0.42      0.54     36645\n",
      "          17       0.77      0.46      0.58     40180\n",
      "          18       0.73      0.27      0.39      4634\n",
      "          19       0.77      0.51      0.61     34337\n",
      "          20       0.71      0.36      0.48     36924\n",
      "          21       0.79      0.58      0.67     28801\n",
      "          22       0.86      0.69      0.76     12568\n",
      "          23       0.66      0.25      0.36      4397\n",
      "          24       0.91      0.92      0.92    244236\n",
      "          25       0.81      0.63      0.71      7699\n",
      "          26       0.88      0.87      0.88    171299\n",
      "          27       0.89      0.80      0.84     67435\n",
      "          28       0.83      0.75      0.78    111328\n",
      "          29       0.80      0.59      0.68     11652\n",
      "          30       0.79      0.55      0.65     23355\n",
      "          31       0.91      0.95      0.93    267472\n",
      "          32       0.78      0.63      0.70     61409\n",
      "          33       0.81      0.68      0.74     63027\n",
      "          34       0.89      0.89      0.89    159181\n",
      "          35       0.88      0.82      0.85    101882\n",
      "          36       0.91      0.87      0.89    133943\n",
      "          37       0.89      0.86      0.88    171307\n",
      "          38       0.81      0.66      0.73     48479\n",
      "          39       0.90      0.83      0.87     96554\n",
      "          40       0.92      0.91      0.91    201269\n",
      "          41       0.91      0.94      0.93    269154\n",
      "          42       0.82      0.65      0.73     45701\n",
      "          43       0.67      0.02      0.04       282\n",
      "          44       0.78      0.56      0.65     11544\n",
      "          45       0.75      0.49      0.59     35789\n",
      "\n",
      "   micro avg       0.87      0.79      0.83   3478643\n",
      "   macro avg       0.80      0.60      0.66   3478643\n",
      "weighted avg       0.86      0.79      0.82   3478643\n",
      " samples avg       0.88      0.82      0.83   3478643\n",
      "\n",
      "Accuracy:  0.22793072396626815\n",
      "Hamming Loss:  0.06918387860196051\n",
      "END\n",
      "2021-01-05 22:52:55.065257\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, hamming_loss\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "print(\"CLASSIFICATION START\")\n",
    "print(datetime.datetime.now())\n",
    "svmClassifier = OneVsRestClassifier(LinearSVC(), n_jobs=-1)\n",
    "svmClassifier.fit(vectorised_train_abstracts, train_labels)\n",
    "\n",
    "svmPreds = svmClassifier.predict(vectorised_test_abstracts)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, svmPreds))\n",
    "print(\"Accuracy: \", accuracy_score(test_labels, svmPreds))\n",
    "print(\"Hamming Loss: \", hamming_loss(test_labels, svmPreds))\n",
    "print(\"END\")\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we consider the computation time, the recall, precision and f1-score, LinearSVC is a good classifier for this use case. It took only 1 hour and 22 minutes do load 1.7 million datasampels, preprocess the text, train the classifier and test the classifier in comparison to the total computation time of decision tree with 8 hours and 24 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to this approach would be to use the deep learning model BERT or achieve text classification with an RNN (recurrent neural network). For these alternative there are examples for text classification on the tensorflow webpage. With this and the large dataset, even better results could be achieved. The downside of these alternatives is that they need a lot more time to train."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
